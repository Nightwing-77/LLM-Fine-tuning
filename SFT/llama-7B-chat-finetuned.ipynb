{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d228745-efdf-4bb2-95f7-50430b15e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://repo.radeon.com/amdgpu/30.10_rc1/ubuntu noble InRelease\n",
      "Hit:2 https://repo.radeon.com/graphics/7.0_rc1/ubuntu noble InRelease          \u001b[0m\u001b[33m\n",
      "Hit:3 https://repo.radeon.com/rocm/apt/7.0_rc1 noble InRelease                 \u001b[0m\n",
      "Get:4 http://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]      \u001b[0m\u001b[33m\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu noble InRelease   \u001b[0m\u001b[33m\n",
      "Get:6 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages [1136 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu noble-security/main amd64 Packages [1474 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [2376 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Packages [34.6 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]     \u001b[0m\u001b[33m\n",
      "Get:12 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [1828 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [1923 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [2483 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu noble-backports/main amd64 Packages [79.2 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu noble-backports/universe amd64 Packages [38.3 kB]\n",
      "Fetched 11.8 MB in 1s (8389 kB/s)[33m                        \u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "22 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "The following additional packages will be installed:\n",
      "  git-man less libcbor0.10 liberror-perl libfido2-1 libxmuu1 openssh-client\n",
      "  xauth\n",
      "Suggested packages:\n",
      "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-email git-gui\n",
      "  gitk gitweb git-cvs git-mediawiki git-svn keychain libpam-ssh monkeysphere\n",
      "  ssh-askpass\n",
      "The following NEW packages will be installed:\n",
      "  git git-man less libcbor0.10 liberror-perl libfido2-1 libxmuu1\n",
      "  openssh-client xauth\n",
      "0 upgraded, 9 newly installed, 0 to remove and 22 not upgraded.\n",
      "Need to get 5997 kB of archives.\n",
      "After this operation, 28.9 MB of additional disk space will be used.\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package less.\n",
      "(Reading database ... 95088 files and directories currently installed.)\n",
      "Preparing to unpack .../0-less_590-2ubuntu2.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking less (590-2ubuntu2.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  5%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libcbor0.10:amd64.\n",
      "Preparing to unpack .../1-libcbor0.10_0.10.2-1.2ubuntu2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libcbor0.10:amd64 (0.10.2-1.2ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libfido2-1:amd64.\n",
      "Preparing to unpack .../2-libfido2-1_1.14.0-1build3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking libfido2-1:amd64 (1.14.0-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libxmuu1:amd64.\n",
      "Preparing to unpack .../3-libxmuu1_2%3a1.1.3-3build2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libxmuu1:amd64 (2:1.1.3-3build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package openssh-client.\n",
      "Preparing to unpack .../4-openssh-client_1%3a9.6p1-3ubuntu13.14_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking openssh-client (1:9.6p1-3ubuntu13.14) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package xauth.\n",
      "Preparing to unpack .../5-xauth_1%3a1.1.2-1build1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking xauth (1:1.1.2-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package liberror-perl.\n",
      "Preparing to unpack .../6-liberror-perl_0.17029-2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Unpacking liberror-perl (0.17029-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package git-man.\n",
      "Preparing to unpack .../7-git-man_1%3a2.43.0-1ubuntu7.3_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking git-man (1:2.43.0-1ubuntu7.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package git.\n",
      "Preparing to unpack .../8-git_1%3a2.43.0-1ubuntu7.3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking git (1:2.43.0-1ubuntu7.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up libcbor0.10:amd64 (0.10.2-1.2ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up less (590-2ubuntu2.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up liberror-perl (0.17029-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up git-man (1:2.43.0-1ubuntu7.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libfido2-1:amd64 (1.14.0-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libxmuu1:amd64 (2:1.1.3-3build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up openssh-client (1:9.6p1-3ubuntu13.14) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up git (1:2.43.0-1ubuntu7.3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up xauth (1:1.1.2-1build1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for libc-bin (2.39-0ubuntu8.5) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!sudo apt update && sudo apt install git -y -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ddd192-7695-432c-a72e-82f970296b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.8.0\n",
      "Uninstalling torch-2.8.0:\n",
      "  Successfully uninstalled torch-2.8.0\n",
      "Found existing installation: torchvision 0.19.1+rocm6.0\n",
      "Uninstalling torchvision-0.19.1+rocm6.0:\n",
      "  Successfully uninstalled torchvision-0.19.1+rocm6.0\n",
      "Found existing installation: torchaudio 2.4.1+rocm6.0\n",
      "Uninstalling torchaudio-2.4.1+rocm6.0:\n",
      "  Successfully uninstalled torchaudio-2.4.1+rocm6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8616df8-db8d-477b-bd83-22db9087bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/rocm6.0\n",
      "Collecting torch==2.4.1+rocm6.0\n",
      "  Downloading https://download.pytorch.org/whl/rocm6.0/torch-2.4.1%2Brocm6.0-cp312-cp312-linux_x86_64.whl (2363.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 GB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m  \u001b[33m0:00:32\u001b[0mm0:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting torchvision==0.19.1+rocm6.0\n",
      "  Downloading https://download.pytorch.org/whl/rocm6.0/torchvision-0.19.1%2Brocm6.0-cp312-cp312-linux_x86_64.whl (65.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.4.1+rocm6.0\n",
      "  Downloading https://download.pytorch.org/whl/rocm6.0/torchaudio-2.4.1%2Brocm6.0-cp312-cp312-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pytorch-triton-rocm==3.0.0 (from torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/pytorch_triton_rocm-3.0.0-cp312-cp312-linux_x86_64.whl (341.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.7/341.7 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy (from torchvision==0.19.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.19.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.1+rocm6.0)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m339.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m293.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/numpy-2.1.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m425.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m417.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, setuptools, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, pytorch-triton-rocm, jinja2, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━\u001b[0m \u001b[32m 0/15\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.015\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:━━\u001b[0m \u001b[32m 0/15\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [sympy]ensions]\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: numpy[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [pillow]ols]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling numpy-2.3.3:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.3━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.2━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.2:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.9.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling fsspec-2025.9.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.9.00m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: jinja2━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [pytorch-triton-rocm]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [pytorch-triton-rocm]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [pytorch-triton-rocm]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.6m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [pytorch-triton-rocm]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [torchaudio]5\u001b[0m [torchaudio]]ocm]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 pillow-11.0.0 pytorch-triton-rocm-3.0.0 setuptools-70.2.0 sympy-1.13.3 torch-2.4.1+rocm6.0 torchaudio-2.4.1+rocm6.0 torchvision-0.19.1+rocm6.0 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.4.1+rocm6.0 torchvision==0.19.1+rocm6.0 torchaudio==2.4.1+rocm6.0 --index-url https://download.pytorch.org/whl/rocm6.0 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e19dc4-8e45-423c-9267-5afcd72e4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets huggingface-hub scipy -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41da496b-4893-475d-bf50-5051e3b92904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is a ROCm-GPU detected?  True\n",
      "How many ROCm-GPUs are detected?  1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is a ROCm-GPU detected? \", torch.cuda.is_available())\n",
    "print(\"How many ROCm-GPUs are detected? \", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e830f2-ec0b-4f2a-bc14-10fccab67dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================ ROCm System Management Interface ============================\n",
      "====================================== Product Info ======================================\n",
      "GPU[0]\t\t: Card Series: \t\tAMD Instinct MI300X VF\n",
      "GPU[0]\t\t: Card Model: \t\t0x74b5\n",
      "GPU[0]\t\t: Card Vendor: \t\tAdvanced Micro Devices, Inc. [AMD/ATI]\n",
      "GPU[0]\t\t: Card SKU: \t\tM3000100\n",
      "GPU[0]\t\t: Subsystem ID: \t0x74a1\n",
      "GPU[0]\t\t: Device Rev: \t\t0x00\n",
      "GPU[0]\t\t: Node ID: \t\t1\n",
      "GPU[0]\t\t: GUID: \t\t21947\n",
      "GPU[0]\t\t: GFX Version: \t\tgfx942\n",
      "==========================================================================================\n",
      "================================== End of ROCm SMI Log ===================================\n"
     ]
    }
   ],
   "source": [
    "!rocm-smi --showproductname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1ef6f36-849b-4e69-b24b-1d18b3c9c8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "/bin/bash: line 1: fg: no job control\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7543f5d6-406a-4f55-9bb9-82158c99ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bitsandbytes'...\n",
      "remote: Enumerating objects: 10497, done.\u001b[K\n",
      "remote: Counting objects: 100% (609/609), done.\u001b[K\n",
      "remote: Compressing objects: 100% (269/269), done.\u001b[K\n",
      "remote: Total 10497 (delta 507), reused 340 (delta 340), pack-reused 9888 (from 5)\u001b[K\n",
      "Receiving objects: 100% (10497/10497), 3.60 MiB | 31.80 MiB/s, done.\n",
      "Resolving deltas: 100% (7022/7022), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ROCm/bitsandbytes.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a005dea-4368-420e-8aaa-f998d6f78446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd bitsandbytes\n",
    "!git checkout rocm_enabled_multi_backend\n",
    "!pip install -r requirements-dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2051a6-ed75-4358-bfe6-4225e47a3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cmake -DBNB_ROCM_ARCH=\"gfx942\" -DCOMPUTE_BACKEND=hip -S .\n",
    "!python setup.py install -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c1dfc57-e7b0-4fbb-a1be-3f3fadab0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U transformers\n",
    "%pip install -U datasets \n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b81e05-7e68-4680-83f7-5cc84fcb60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall transformers -y\n",
    "!pip install transformers --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b07a440-05f9-44d0-b08a-fe81624c1317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+rocm6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "from transformers import AutoTokenizer  # Try this first, not AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7649dd80-25c3-4771-8263-151aadefda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf325da-a25f-4878-8c01-4b59097a4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from huggingface_hub import login\n",
    "login(token=os.environ[\"HUGGING_FACE_TOKEN\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d75bd71-3871-4ead-9b10-9cb198cae3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli whoami' is deprecated. Use 'hf auth whoami' instead.\u001b[0m\n",
      "Advik-7\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36691e8-6e10-4ff5-81ac-4580b283fa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f8b8f2582f4b6fae29d35fd000db13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607b941f2cd14d7ba49482780940307a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67204d119be84467a9b1b3672637d73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acabc82277846a19342073899e73fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05ed8be211343c2944c507f7c9d668e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36f6fbdb81b4947834cfcc7605af39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c56b18b85c4e66a7ea60577087be02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63b921467c6483f9a2f04331ae9c48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9506683b40487f9e6e931e759532c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88653923078c44e99287414845edb0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06865dc3d4364f14926d06d8648e3dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "device = \"cuda:0\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name, trust_remote_code = True).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model_name,\n",
    "        trust_remote_code = True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45d3ab63-6c9c-46c0-9bc7-a578fac96dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9274d375b48748af8758f04e36d35488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dbc3fdbde34c57adf097f76565301e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-9ad84bb9cf65a4(…):   0%|          | 0.00/967k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936635ac543742fa93e989ebe7b43d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
    "training_dataset = load_dataset(training_dataset_name, split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "349f2584-30aa-4f22-a1ba-55622b1ef593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce289684-46b2-4f40-a193-bffa493ac8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '<s>[INST] write me a 1000 words essay about deez nuts. [/INST] The Deez Nuts meme first gained popularity in 2015 on the social media platform Vine. The video featured a young man named Rodney Bullard, who recorded himself asking people if they had heard of a particular rapper. When they responded that they had not, he would respond with the phrase \"Deez Nuts\" and film their reactions. The video quickly went viral, and the phrase became a popular meme. \\n\\nSince then, Deez Nuts has been used in a variety of contexts to interrupt conversations, derail discussions, or simply add humor to a situation. It has been used in internet memes, in popular music, and even in politics. In the 2016 US presidential election, a 15-year-old boy named Brady Olson registered as an independent candidate under the name Deez Nuts. He gained some traction in the polls and even made appearances on national news programs.\\n\\nThe Deez Nuts meme has had a significant impact on popular culture. It has become a recognizable catchphrase that people use to add humor to everyday conversations. The meme has also been used to satirize politics and other serious issues. For example, in 2016, a group of activists in the UK used the phrase \"Deez Nuts for President\" as part of a campaign to encourage young people to vote in the EU referendum. </s><s>[INST] Rewrite the essay in a more casual way. Instead of sounding proffesional, sound like a college student who is forced to write the essay but refuses to do so in the propper way. Use casual words and slang when possible. [/INST] Yo, so you want me to write a 1000-word essay about Deez Nuts? Alright, fine. So, this whole thing started on Vine back in 2015. Some dude named Rodney Bullard made a video where he would ask people if they knew a rapper, and when they said no, he would hit them with the classic line: \"Deez Nuts!\" People loved it, and it became a viral meme.\\n\\nNowadays, Deez Nuts is used for all kinds of stuff. You can throw it out there to interrupt someone or just to be funny. It\\'s all over the internet, in music, and even in politics. In fact, during the 2016 US presidential election, a kid named Brady Olson registered as an independent candidate under the name Deez Nuts. He actually got some attention from the media and made appearances on TV and everything.\\n\\nThe impact of Deez Nuts on our culture is pretty huge. It\\'s become a thing that everyone knows and uses to add some humor to their everyday conversations. Plus, people have used it to make fun of politics and serious issues too. Like, in the UK, some groups of activists used the phrase \"Deez Nuts for President\" to encourage young people to vote in the EU referendum.\\n\\nThere you have it, a thousand words about Deez Nuts in a more casual tone. Can I go back to playing video games now? </s>'}\n"
     ]
    }
   ],
   "source": [
    "print(training_dataset[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4262be42-231a-4956-8d6f-5af06eab7d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02f719a4-e7f7-48fb-8d2d-009e3d5e41e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/venv/lib/python3.12/site-packages (from tensorboard) (2.1.2)\n",
      "Requirement already satisfied: packaging in /opt/venv/lib/python3.12/site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: pillow in /opt/venv/lib/python3.12/site-packages (from tensorboard) (11.0.0)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/venv/lib/python3.12/site-packages (from tensorboard) (70.2.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /opt/venv/lib/python3.12/site-packages (from grpcio>=1.48.2->tensorboard) (4.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m179.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, absl-py, tensorboard\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [tensorboard]\u001b[0m [tensorboard]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 grpcio-1.75.1 markdown-3.9 protobuf-6.32.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "981a45dc-6666-4f25-ae6a-ab65b2110005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.state import AcceleratorState\n",
    "\n",
    "# Reset the accelerator state\n",
    "AcceleratorState._reset_state(reset_partial_state=True)\n",
    "\n",
    "# Then proceed with your training\n",
    "from torch.optim import AdamW\n",
    "from transformers import TrainingArguments\n",
    "# training params\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "         num_train_epochs = 5,\n",
    "         per_device_train_batch_size = 4,\n",
    "         gradient_accumulation_steps = 1,\n",
    "         optim = \"adamw_torch\",\n",
    "         save_steps = 750,\n",
    "         logging_steps = 50,\n",
    "         learning_rate = 4e-5,\n",
    "         weight_decay = 0.001,\n",
    "         fp16=False,\n",
    "         bf16=False,\n",
    "         max_grad_norm = 0.3,\n",
    "         max_steps = -1,\n",
    "         warmup_ratio = 0.03,\n",
    "         group_by_length = True,\n",
    "         lr_scheduler_type = \"constant\",\n",
    "         report_to = \"tensorboard\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer_full = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=training_dataset,\n",
    "    args=training_arguments\n",
    ")\n",
    "trainer_full.save_model(\"checkpoints/last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8976924-503e-47bc-bd35-36e87ed21494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6738415616 || all params: 6738415616 || trainable%: 100.00\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    # Prints the number of trainable parameters in the model.\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\")\n",
    "\n",
    "trainer_full.peft_config = None\n",
    "print_trainable_parameters(trainer_full.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2680adf-276a-405c-93ba-fef99b038614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 36:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.496800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.563500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.620600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.571100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.670200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.674600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.396600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.411800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.398500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.281500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.251700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.288200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.200800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.204600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.223700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.606154972076416, metrics={'train_runtime': 2219.7412, 'train_samples_per_second': 2.253, 'train_steps_per_second': 0.563, 'total_flos': 8.521332485308416e+16, 'train_loss': 0.606154972076416, 'epoch': 5.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer_full.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15627899-6b84-4fd1-b866-9facca9a35b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: AMD Instinct MI300X VF\n",
      "Total Memory: 205.82 GB\n",
      "Allocated Memory: 80.86 GB\n",
      "Cached Memory: 140.38 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu = torch.cuda.current_device()\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(gpu)}\")\n",
    "    print(f\"Total Memory: {torch.cuda.get_device_properties(gpu).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Allocated Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"Cached Memory: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25eb47-8fbf-4ac9-a6d3-da08d6eeb1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a88f914f278451197d698e9603b595b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8788f552d1a4846a45314a3e35bb826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9304847243d441bea65c7bf6819c88c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_path = \"results\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "# Push to hub\n",
    "model.push_to_hub(\"Advik-7/llama2-7b-chat-finetuned\")\n",
    "tokenizer.push_to_hub(\"Advik-7/llama2-7b-chat-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174caec4-1fda-439b-9c3d-d55ca5aeaa32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b93823a-ec0e-4da9-9268-9fe20a8d51c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
